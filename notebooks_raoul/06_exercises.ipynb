{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercises \n",
    "\n",
    "## 0. Setup your own repo\n",
    "- Dont work in this repo. This is my material for lessons. Set up your own repo to work in. Use `MADS-ML-{yourname}` as a format, eg `MADS-ML-JoostB`.\n",
    "- You can add `mads_datasets` and `mltrainer` as dependencies to your own repo, in addition to more basic things like jupyter, torch and seaborn.\n",
    "- If you want to use the tomlserializer, add `tomlserializer` as a dependency. For tensorboard, add `tensorboard` and `torch-tb-profiler`.\n",
    "- Invite me (raoulg; https://github.com/raoulg) as a collaborator to your repo.\n",
    "\n",
    "# 1. Tune the network\n",
    "Run the experiment below, explore the different parameters (see suggestions below) and study the result with tensorboard. \n",
    "Make a single page (1 a4) report of your findings. Use your visualisation skills to communicate your most important findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mads_datasets import DatasetFactoryProvider, DatasetType\n",
    "\n",
    "from mltrainer.preprocessors import BasePreprocessor\n",
    "from mltrainer import imagemodels, Trainer, TrainerSettings, ReportTypes, metrics\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "from tomlserializer import TOMLSerializer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using `tomlserializer` to easily keep track of our experiments, and to easily save the different things we did during our experiments.\n",
    "It can export things like settings and models to a simple `toml` file, which can be easily shared, checked and modified.\n",
    "\n",
    "First, we need the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashionfactory = DatasetFactoryProvider.create_factory(DatasetType.FASHION)\n",
    "preprocessor = BasePreprocessor()\n",
    "streamers = fashionfactory.create_datastreamer(batchsize=64, preprocessor=preprocessor)\n",
    "train = streamers[\"train\"]\n",
    "valid = streamers[\"valid\"]\n",
    "trainstreamer = train.stream()\n",
    "validstreamer = valid.stream()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a way to determine how well our model is performing. We will use accuracy as a metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = metrics.Accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can set up a single experiment.\n",
    "\n",
    "- We will show the model batches of 64 images, \n",
    "- and for every epoch we will show the model 100 batches (trainsteps=100).\n",
    "- then, we will test how well the model is doing on unseen data (teststeps=100).\n",
    "- we will report our results during training to tensorboard, and report all configuration to a toml file.\n",
    "- we will log the results into a directory called \"modellogs\", but you could change this to whatever you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "settings = TrainerSettings(\n",
    "    epochs=5,\n",
    "    metrics=[accuracy],\n",
    "    logdir=\"modellogs\",\n",
    "    train_steps=len(train),\n",
    "    valid_steps=len(valid),\n",
    "    reporttypes=[ReportTypes.TENSORBOARD, ReportTypes.TOML],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a very basic model: a model with three linear layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, num_classes: int, units1: int, units2: int, units3:int = None) -> None:\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.units1 = units1\n",
    "        self.units2 = units2\n",
    "        self.units3 = units3\n",
    "        self.flatten = nn.Flatten()\n",
    "        # Als units3 None is, maak netwerk met 2 hidden layers\n",
    "        if units3 is None:\n",
    "            self.linear_relu_stack = nn.Sequential(\n",
    "                nn.Linear(28 * 28, units1),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(units1, units2),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(units2, num_classes),\n",
    "            )\n",
    "        # Anders maak netwerk met 3 hidden layers\n",
    "        else:\n",
    "            self.linear_relu_stack = nn.Sequential(\n",
    "                nn.Linear(28 * 28, units1),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(units1, units2),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(units2, units3),\n",
    "                nn.ReLU(),  \n",
    "                nn.Linear(units2, units3),\n",
    "                nn.ReLU(),                             \n",
    "                nn.Linear(units3, num_classes),\n",
    "            )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork(\n",
    "    num_classes=10, units1=64, units2=64)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I developped the `tomlserializer` package, it is a useful tool to save configs, models and settings as a tomlfile; that way it is easy to track what you changed during your experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tomlserializer = TOMLSerializer()\n",
    "tomlserializer.save(settings, \"settings.toml\")\n",
    "tomlserializer.save(model, \"model.toml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the `settings.toml` and `model.toml` files to see what is in there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the `Trainer` class from my `mltrainer` module to train your model. It has the TOMLserializer integrated, so it will automatically save the settings and model to a toml file if you have added `TOML` as a reporttype in the settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    settings=settings,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optim.Adam,\n",
    "    traindataloader=trainstreamer,\n",
    "    validdataloader=validstreamer,\n",
    "    scheduler=optim.lr_scheduler.ReduceLROnPlateau\n",
    ")\n",
    "trainer.loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, check in the modellogs directory the results of your experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now loop this with a naive approach, called a grid-search (why do you think i call it naive?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = [512,256, 128, 64,32,16]\n",
    "for unit1 in units:\n",
    "    for unit2 in units:\n",
    "        print(f\"Units: {unit1}, {unit2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = [784, 512, 256, 128, 64, 32, 16]\n",
    "for unit1 in units:\n",
    "    for unit2 in units:\n",
    "        if unit2 < unit1:  \n",
    "            print(f\"Units: {unit1}, {unit2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = [784, 512, 256, 128, 64]\n",
    "for unit1 in units:\n",
    "    for unit2 in units:\n",
    "        if unit2 <= unit1:  \n",
    "            for unit3 in units:\n",
    "                if unit3 <= unit2:  \n",
    "                    print(f\"Units: {unit1}, {unit2}, {unit3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, this might not be the best way to search for a model; some configurations will be better than others (can you predict up front what will be the best configuration?).\n",
    "\n",
    "So, feel free to improve upon the gridsearch by adding your own logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "units = [256, 128, 64]\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "settings = TrainerSettings(\n",
    "    epochs=15,\n",
    "    metrics=[accuracy],\n",
    "    logdir=\"modellogs\",\n",
    "    train_steps=len(train),\n",
    "    valid_steps=len(valid),\n",
    "    reporttypes=[ReportTypes.TENSORBOARD, ReportTypes.TOML],\n",
    ")\n",
    "\n",
    "for unit1 in units:\n",
    "    for unit2 in units:\n",
    "        if unit2 <= unit1:  \n",
    "\n",
    "            model = NeuralNetwork(num_classes=10, units1=unit1, units2=unit2)\n",
    "\n",
    "            trainer = Trainer(\n",
    "                model=model,\n",
    "                settings=settings,\n",
    "                loss_fn=loss_fn,\n",
    "                optimizer=optim.Adam,\n",
    "                traindataloader=trainstreamer,\n",
    "                validdataloader=validstreamer,\n",
    "                scheduler=optim.lr_scheduler.ReduceLROnPlateau\n",
    "            )\n",
    "            trainer.loop()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "units = [512, 128, 64]\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "settings = TrainerSettings(\n",
    "    epochs=8,\n",
    "    metrics=[accuracy],\n",
    "    logdir=\"modellogs\",\n",
    "    train_steps=len(train),\n",
    "    valid_steps=len(valid),\n",
    "    reporttypes=[ReportTypes.TENSORBOARD, ReportTypes.TOML],\n",
    ")\n",
    "\n",
    "for unit1 in units:\n",
    "    for unit2 in units:\n",
    "        if unit2 <= unit1:  \n",
    "\n",
    "                model = NeuralNetwork(num_classes=10, units1=unit1, units2=unit2, units3=unit3)\n",
    "\n",
    "                trainer = Trainer(\n",
    "                    model=model,\n",
    "                    settings=settings,\n",
    "                    loss_fn=loss_fn,\n",
    "                    optimizer=optim.Adam,\n",
    "                    traindataloader=trainstreamer,\n",
    "                    validdataloader=validstreamer,\n",
    "                    scheduler=optim.lr_scheduler.ReduceLROnPlateau\n",
    "                )\n",
    "                trainer.loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we have set the ReportType to TOML, you will find in every log dir a model.toml and settings.toml file."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the experiment, and study the result with tensorboard. \n",
    "\n",
    "Locally, it is easy to do that with VS code itself. On the server, you have to take these steps:\n",
    "\n",
    "- in the terminal, `cd` to the location of the repository\n",
    "- activate the python environment for the shell. Note how the correct environment is being activated.\n",
    "- run `tensorboard --logdir=modellogs` in the terminal\n",
    "- tensorboard will launch at `localhost:6006` and vscode will notify you that the port is forwarded\n",
    "- you can either press the `launch` button in VScode or open your local browser at `localhost:6006`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Report\n",
    "## 1. experiment\n",
    "Experiment with things like:\n",
    "- change the number of epochs, eg to 5 or 10. \n",
    "- changing the amount of units1 and units2 to values between 16 and 1024. Use factors of 2 to easily scan the ranges: 16, 32, 64, etc.\n",
    "- changing the batchsize to values between 4 and 128. Again, use factors of two for convenience.\n",
    "- change the depth of your model by adding a additional linear layer + activation function\n",
    "- changing the learningrate to values between 1e-2 and 1e-5 \n",
    "- changing the optimizer from SGD to one of the other available algoritms at [torch](https://pytorch.org/docs/stable/optim.html) (scroll down for the algorithms)\n",
    "\n",
    "Check the results:\n",
    "- all your experiments are saved in the `modellogs` directory, with a timestamp. Inside you find a model.toml file, that \n",
    "contains all the settings of the model. The `events` file is what tensorboard will show.\n",
    "- visualize the relationship between variables: for example, make a heatmap of units vs layers.\n",
    "\n",
    "Studyquestions:\n",
    "- Epochs: what is the upside, what is the downside of increasing epochs? Do you need more epochs to find out which configuration is best? When do you need that, when not?\n",
    "- what is an upside of using factors of 2 for hypertuning? What is a downside?\n",
    "\n",
    "## Note\n",
    "A note on train_steps: this is a setting that determines how often you get an update. \n",
    "Because our complete dataset is 938 (60000 / 64) batches long, you will need 938 trainstep to cover the complete 60.000 images.\n",
    "\n",
    "This can actually be a bit confusion for some students, because changing the value of trainsteps 938 changes the meaning of an `epoch` slightly, because one epoch is no longer the full dataset, but simply `trainstep` batches. Setting trainsteps to 100 means you need to wait twice as long before you get feedback on the performance, as compared to trainsteps=50. You will see that settings trainsteps to 100 improves the learning, but that is simply because the model has seen twice as much examples as compared to trainsteps=50.\n",
    "\n",
    "This implies that it is not usefull to compare trainsteps=50 and trainsteps=100, because setting it to 100 will always be better.\n",
    "Just pick an amount that works for your hardware & patience, and adjust your number of epochs accordingly (increase epochs with lower values for trainsteps)\n",
    "\n",
    "# 2. Reflect\n",
    "Doing a master means you don't just start engineering a pipeline, but you need to reflect. Why do you see the results you see? What does this mean, considering the theory? Write down lessons learned and reflections, based on experimental results. This is the `science` part of `data science`.\n",
    "\n",
    "You follow this cycle:\n",
    "- make a hypothesis\n",
    "- design an experiment\n",
    "- run the experiment\n",
    "- analyze the results and draw conclusions\n",
    "- repeat\n",
    "\n",
    "## Tip\n",
    "To keep track of this process, it is useful to keep a journal. While you could use anything to do so, a nice command line tool is [jrnl](https://jrnl.sh/en/stable/). This gives you the advantage of staying in the terminal, just type down your ideas during the process, and you can always look back at what you have done.\n",
    "Try to first formulate a hypothesis, and then design an experiment to test it. This will help you to stay focused on the goal, and not get lost in the data.\n",
    "\n",
    "Important: the report you write is NOT the same as your journal! The journal will help you to keep track of your process, and later write down a reflection on what you have done where you draw conclusion, reflecting back on the theory.\n",
    "\n",
    "# 3. Make a short report\n",
    "Make a short 1 a4 page report of your findings.\n",
    "pay attention to:\n",
    "- what was your hypothesis about interaction between hyperparameters?\n",
    "- what did you find?\n",
    "- visualise your results about the relationship between hyperparameters.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
